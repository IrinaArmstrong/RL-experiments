{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from time import sleep\n",
    "from collections import namedtuple, OrderedDict\n",
    "from typing import List, Dict, NoReturn, Tuple, Optional, Any\n",
    "\n",
    "# Visualization pretty\n",
    "from pprint import pprint\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# NNs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configue GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    print(device, n_gpu)\n",
    "    torch.cuda.get_device_name(0) \n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "**Description:** <br>\n",
    "        A pole is attached by an un-actuated joint to a cart, which moves along\n",
    "        a frictionless track. The pendulum starts upright, and the goal is to\n",
    "        prevent it from falling over by increasing and reducing the cart's\n",
    "        velocity.\n",
    "        \n",
    "**Source:** <br>\n",
    "        This environment corresponds to the version of the cart-pole problem\n",
    "        described by Barto, Sutton, and Anderson\n",
    "        \n",
    "**Observation:** <br>\n",
    "        Type: Box(4) <br>\n",
    "        \n",
    "| Num | Observation | Min | Max |\n",
    "| --- | --- | --- | --- |\n",
    "| 0 | Cart Position          |   -4.8                 |  4.8 |\n",
    "| 1 | Cart Velocity          |  -Inf                  |  Inf |\n",
    "| 2 | Pole Angle             |   -0.418 rad (-24 deg) |  0.418 rad (24 deg) |\n",
    "| 3 | Pole Angular Velocity  |   -Inf                 |  Inf |\n",
    "        \n",
    "**Actions:** <br>\n",
    "        Type: Discrete(2) <br>\n",
    "        Num   Action <br>\n",
    "* 0     Push cart to the left\n",
    "* 1     Push cart to the right\n",
    "\n",
    "> Note: The amount the velocity that is reduced or increased is not\n",
    "        fixed; it depends on the angle the pole is pointing. This is because\n",
    "        the center of gravity of the pole increases the amount of energy needed\n",
    "        to move the cart underneath it\n",
    "        \n",
    "**Reward:** <br>\n",
    "        Reward is 1 for every step taken, including the termination step\n",
    "        \n",
    "**Starting State:** <br>\n",
    "        All observations are assigned a uniform random value in [-0.05..0.05]\n",
    "        \n",
    "**Episode Termination:** <br>\n",
    "* Pole Angle is more than 12 degrees.\n",
    "* Cart Position is more than 2.4 (center of the cart reaches the edge of the display).\n",
    "* Episode length is greater than 200.\n",
    "* Solved Requirements:\n",
    "* Considered solved when the average return is greater than or equal to 195.0 over 100 consecutive trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: 2\n",
      "Observation space: shape (4,),\n",
      "[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38] to [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "# loading Cartpole environment from gym\n",
    "env = gym.make('CartPole-v1')\n",
    "env.seed(seed=11)\n",
    "print(f\"Action space: {env.action_space.n}\")  \n",
    "# Cart Position, Cart Velocity, Pole Angle, Pole Angular Velocity\n",
    "print(f\"Observation space: shape {env.observation_space.shape},\\n{env.observation_space.low} to {env.observation_space.high}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sime random episodes\n",
    "try:\n",
    "    env.reset()\n",
    "    for _ in range(200):\n",
    "        env.render(mode='human')\n",
    "        clear_output(wait=True)\n",
    "        env.step(env.action_space.sample()) # take a random action\n",
    "finally:\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episode = namedtuple('Episode', field_names=['reward', 'steps'])\n",
    "EpisodeStep = namedtuple('EpisodeStep', field_names=['observation', 'action'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CEM_Agent(nn.Module):\n",
    "    \n",
    "    def __init__(self, env, device, h_size: int = 16):\n",
    "        super(CEM_Agent, self).__init__()\n",
    "        self._env = env\n",
    "        # state, hidden layer, action sizes\n",
    "        if len(env.observation_space.shape) == 0:\n",
    "            self._state_size = env.observation_space.n\n",
    "        else:\n",
    "            self._state_size = env.observation_space.shape[0]\n",
    "        self._hidd_size = h_size\n",
    "        if len(env.action_space.shape) == 0:\n",
    "            self._act_size = env.action_space.n\n",
    "        else:\n",
    "            self._act_size = env.action_space.shape[0]\n",
    "        self._device = device\n",
    "        # define net\n",
    "        self._net = nn.Sequential(OrderedDict([\n",
    "            (\"fc1\", nn.Linear(self._state_size, self._hidd_size)),\n",
    "            (\"relu\", nn.ReLU()),\n",
    "            (\"fc2\", nn.Linear(self._hidd_size, self._act_size))\n",
    "        ])).to(self._device)\n",
    "        self.__n_params = self.__count_parameters()\n",
    "        \n",
    "        \n",
    "    def __count_parameters(self) -> int:\n",
    "        return np.sum([c._parameters.get('weight').data.flatten().shape[0] +\n",
    "                       c._parameters.get('bias').data.flatten().shape[0]\n",
    "                       for i, c in self._net.named_children() \n",
    "                       if len(c._parameters.keys()) > 0])\n",
    "                \n",
    "        \n",
    "    def set_weights(self, weights: np.ndarray):\n",
    "        assert(weights.shape[0] == self.__n_params)\n",
    "        layers = dict(net.named_children())\n",
    "        fc1_end = self._state_size * self._hidd_size + self._hidd_size\n",
    "        # fc1\n",
    "        fc1_w = torch.from_numpy(weights[:self._state_size * self._hidd_size].reshape(self._state_size, \n",
    "                                                                                        self._hidd_size)).to(self._device)\n",
    "        fc1_b = torch.from_numpy(weights[(self._state_size * self._hidd_size):\n",
    "                                         fc1_end].reshape(self._state_size)).to(self._device)\n",
    "        layers.get('fc1')._parameters.get('weight').data.copy_(fc1_w) # .view_as(layers.get('fc1')._parameters.get('weight').data)\n",
    "        layers.get('fc1')._parameters.get('bias').data.copy_(fc1_b)\n",
    "        # fc2\n",
    "        fc2_w = torch.from_numpy(weights[fc1_end:self._act_size * self._hidd_size].reshape(self._act_size, \n",
    "                                                                                        self._hidd_size)).to(self._device)\n",
    "        fc2_b = torch.from_numpy(weights[(self._act_size * self._hidd_size) \n",
    "                                         :].reshape(self._state_size)).to(self._device)\n",
    "        layers.get('fc2')._parameters.get('weight').data.copy_(fc2_w) \n",
    "        layers.get('fc2')._parameters.get('bias').data.copy_(fc2_b)\n",
    "        \n",
    "        \n",
    "    def forward(self, x) -> np.ndarray:\n",
    "        return F.tanh(self._net(x.float().to(self._device))).cpu().data\n",
    "    \n",
    "    \n",
    "    def evaluate(self, weights: np.ndarray, gamma: float = 1.0, \n",
    "                 max_iters: int = 1000) -> float:\n",
    "        # set given weights\n",
    "        self.set_weights(weights)\n",
    "        # run replay\n",
    "        episode_reward = 0.0\n",
    "        state = self._env.reset()\n",
    "        for t in range(max_iters):\n",
    "            state = torch.from_numpy(state).float().to(self._device)\n",
    "            action = self.forward(state)\n",
    "            state, reward, done, _ = self._env.step(action)\n",
    "            episode_reward += reward * np.power(gamma, t)\n",
    "            if done:\n",
    "                break\n",
    "        return episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Agent\n",
    "agent = CEM_Agent(env, device=device, h_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CEM_Agent(\n",
       "  (_net): Sequential(\n",
       "    (fc1): Linear(in_features=4, out_features=10, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (fc2): Linear(in_features=10, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
