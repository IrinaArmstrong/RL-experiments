{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from time import sleep\n",
    "from collections import namedtuple, OrderedDict, deque\n",
    "from typing import List, Dict, NoReturn, Tuple, Optional, Any\n",
    "\n",
    "# Visualization pretty\n",
    "from pprint import pprint\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# NNs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configue GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    print(device, n_gpu)\n",
    "    torch.cuda.get_device_name(0) \n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "**Description:** <br>\n",
    "        A pole is attached by an un-actuated joint to a cart, which moves along\n",
    "        a frictionless track. The pendulum starts upright, and the goal is to\n",
    "        prevent it from falling over by increasing and reducing the cart's\n",
    "        velocity.\n",
    "        \n",
    "**Source:** <br>\n",
    "        This environment corresponds to the version of the cart-pole problem\n",
    "        described by Barto, Sutton, and Anderson\n",
    "        \n",
    "**Observation:** <br>\n",
    "        Type: Box(4) <br>\n",
    "        \n",
    "| Num | Observation | Min | Max |\n",
    "| --- | --- | --- | --- |\n",
    "| 0 | Cart Position          |   -4.8                 |  4.8 |\n",
    "| 1 | Cart Velocity          |  -Inf                  |  Inf |\n",
    "| 2 | Pole Angle             |   -0.418 rad (-24 deg) |  0.418 rad (24 deg) |\n",
    "| 3 | Pole Angular Velocity  |   -Inf                 |  Inf |\n",
    "        \n",
    "**Actions:** <br>\n",
    "        Type: Discrete(2) <br>\n",
    "        Num   Action <br>\n",
    "* 0     Push cart to the left\n",
    "* 1     Push cart to the right\n",
    "\n",
    "> Note: The amount the velocity that is reduced or increased is not\n",
    "        fixed; it depends on the angle the pole is pointing. This is because\n",
    "        the center of gravity of the pole increases the amount of energy needed\n",
    "        to move the cart underneath it\n",
    "        \n",
    "**Reward:** <br>\n",
    "        Reward is 1 for every step taken, including the termination step\n",
    "        \n",
    "**Starting State:** <br>\n",
    "        All observations are assigned a uniform random value in [-0.05..0.05]\n",
    "        \n",
    "**Episode Termination:** <br>\n",
    "* Pole Angle is more than 12 degrees.\n",
    "* Cart Position is more than 2.4 (center of the cart reaches the edge of the display).\n",
    "* Episode length is greater than 200.\n",
    "* Solved Requirements:\n",
    "* Considered solved when the average return is greater than or equal to 195.0 over 100 consecutive trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: 2\n",
      "Observation space: shape (4,),\n",
      "[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38] to [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "# loading Cartpole environment from gym\n",
    "env = gym.make('CartPole-v1')\n",
    "env.seed(seed=11)\n",
    "print(f\"Action space: {env.action_space.n}\")  \n",
    "# Cart Position, Cart Velocity, Pole Angle, Pole Angular Velocity\n",
    "print(f\"Observation space: shape {env.observation_space.shape},\\n{env.observation_space.low} to {env.observation_space.high}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sime random episodes\n",
    "try:\n",
    "    env.reset()\n",
    "    for _ in range(200):\n",
    "        env.render(mode='human')\n",
    "        clear_output(wait=True)\n",
    "        env.step(env.action_space.sample()) # take a random action\n",
    "finally:\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent\n",
    "Implements classical architecture for CEM method with weights evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episode = namedtuple('Episode', field_names=['reward', 'steps'])\n",
    "EpisodeStep = namedtuple('EpisodeStep', field_names=['observation', 'action'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CEM_Agent(nn.Module):\n",
    "    \n",
    "    def __init__(self, env, device, h_size: int = 16):\n",
    "        super(CEM_Agent, self).__init__()\n",
    "        self._env = env\n",
    "        # state, hidden layer, action sizes\n",
    "        if len(env.observation_space.shape) == 0:\n",
    "            self._state_size = env.observation_space.n\n",
    "        else:\n",
    "            self._state_size = env.observation_space.shape[0]\n",
    "        self._hidd_size = h_size\n",
    "        if len(env.action_space.shape) == 0:\n",
    "            self._act_size = env.action_space.n\n",
    "        else:\n",
    "            self._act_size = env.action_space.shape[0]\n",
    "        self._device = device\n",
    "        print(f\"State size: {self._state_size}, action size: {self._act_size}\")\n",
    "        # define net\n",
    "        self._net = nn.Sequential(OrderedDict([\n",
    "            (\"fc1\", nn.Linear(self._state_size, self._hidd_size)),\n",
    "            (\"relu\", nn.ReLU()),\n",
    "            (\"fc2\", nn.Linear(self._hidd_size, self._act_size))\n",
    "        ])).to(self._device)\n",
    "        self.__n_params = self._count_parameters()\n",
    "        \n",
    "        \n",
    "    def _count_parameters(self) -> int:\n",
    "        return np.sum([c._parameters.get('weight').data.flatten().shape[0] +\n",
    "                       c._parameters.get('bias').data.flatten().shape[0]\n",
    "                       for i, c in self._net.named_children() \n",
    "                       if len(c._parameters.keys()) > 0])\n",
    "                \n",
    "        \n",
    "    def set_weights(self, weights: np.ndarray):\n",
    "        assert(weights.shape[0] == self.__n_params)\n",
    "        layers = dict(self._net.named_children())\n",
    "        fc1_end = (self._state_size * self._hidd_size) + self._hidd_size\n",
    "        # fc1\n",
    "        fc1_w = torch.from_numpy(weights[:self._state_size * self._hidd_size].reshape(self._hidd_size, \n",
    "                                                                                      self._state_size)).to(self._device)\n",
    "        fc1_b = torch.from_numpy(weights[(self._state_size * self._hidd_size):\n",
    "                                         fc1_end].reshape(self._hidd_size)).to(self._device)\n",
    "#         print(f\"fc1 weights: {fc1_w.shape}, bias: {fc1_b.shape}, fc1_end: {fc1_end}\")\n",
    "        layers.get('fc1')._parameters.get('weight').data.copy_(fc1_w) # .view_as(layers.get('fc1')._parameters.get('weight').data)\n",
    "        layers.get('fc1')._parameters.get('bias').data.copy_(fc1_b)\n",
    "        # fc2\n",
    "        fc2_w = torch.from_numpy(weights[fc1_end: fc1_end + self._act_size * self._hidd_size].reshape(self._act_size, \n",
    "                                                                                        self._hidd_size)).to(self._device)\n",
    "        fc2_b = torch.from_numpy(weights[fc1_end + (self._act_size * self._hidd_size) \n",
    "                                         :].reshape(self._act_size)).to(self._device)\n",
    "#         print(f\"fc2 weights: {fc2_w.shape}, bias: {fc2_b.shape}\")\n",
    "        layers.get('fc2')._parameters.get('weight').data.copy_(fc2_w) \n",
    "        layers.get('fc2')._parameters.get('bias').data.copy_(fc2_b)\n",
    "        \n",
    "        \n",
    "    def forward(self, x) -> np.ndarray:\n",
    "        return F.tanh(self._net(x.float().to(self._device))).cpu().data\n",
    "    \n",
    "    \n",
    "    def evaluate(self, weights: np.ndarray, gamma: float = 1.0, \n",
    "                 max_iters: int = 1000) -> float:\n",
    "        # set given weights\n",
    "        self.set_weights(weights)\n",
    "        # run replay\n",
    "        episode_reward = 0.0\n",
    "        state = self._env.reset()\n",
    "        for t in range(max_iters):\n",
    "            state = torch.from_numpy(state).float().to(self._device)\n",
    "            action = torch.argmax(self.forward(state)).numpy()\n",
    "            state, reward, done, _ = self._env.step(action)\n",
    "            episode_reward += reward * np.power(gamma, t)\n",
    "            if done:\n",
    "                break\n",
    "        return episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=4, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=16, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(OrderedDict([\n",
    "    (\"fc1\", nn.Linear(env.observation_space.shape[0], 10)),\n",
    "    (\"relu\", nn.ReLU()),\n",
    "    (\"fc2\", nn.Linear(16, env.action_space.n))\n",
    "]))\n",
    "for i, c in net.named_children():\n",
    "    if len(c._parameters.keys()) > 0:\n",
    "        print()\n",
    "        print(c._parameters.get('weight').data.shape, \"-->\", c._parameters.get('weight').data.flatten().shape)\n",
    "        print(c._parameters.get('bias').data.shape, \"-->\", c._parameters.get('bias').data.flatten().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Agent with the Cross-Entropy Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_agent_weights(model: nn.Module, dir: str='models-checkpoints',\n",
    "               filename: str='agent.pt'):\n",
    "    \"\"\"\n",
    "    Trained model, configuration and tokenizer,\n",
    "    they can then be reloaded using `from_pretrained()` if using default names.\n",
    "    \"\"\"\n",
    "    # Take care of distributed/parallel training\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model.state_dict()\n",
    "    torch.save(model_to_save, os.path.join(sys.path[0], dir, filename))\n",
    "    # models_checkpoints\n",
    "    print(\"Weights successfully saved.\")\n",
    "    \n",
    "\n",
    "def CEM_Weights(agent: nn.Module, n_train_iterations: int = 500, \n",
    "                max_eval_iterations: int = 1000, train_gamma: float = 1.0, \n",
    "                log_interval: int = 10, population_size: int = 50, \n",
    "                elite_frac: float = 0.2, sigma: float = 0.5):\n",
    "    \"\"\"\n",
    "    PyTorch implementation of the cross-entropy method.\n",
    "    \n",
    "    :param n_train_iterations (int): maximum number of training iterations\n",
    "    :param max_eval_iterations (int): maximum number of timesteps per episode\n",
    "    :param train_gamma (float): discount rate on train\n",
    "    :param log_interval (int): how often to print average score (over last 100 episodes)\n",
    "    :param population_size (int): size of population at each iteration\n",
    "    :param elite_frac (float): percentage of top performers to use in update\n",
    "    :param sigma (float): standard deviation of additive noise\n",
    "    \"\"\"\n",
    "    n_elite = int(population_size * elite_frac)\n",
    "\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    best_weight = sigma * np.random.randn(agent._count_parameters())\n",
    "    best_reward = 0.0\n",
    "    \n",
    "    for iteration in tqdm_notebook(range(1, n_train_iterations + 1)):\n",
    "        # Generate population of weights distributions close to best one\n",
    "        weights_population = [best_weight + (sigma * np.random.randn(agent._count_parameters())) \n",
    "                              for _ in range(population_size)]\n",
    "        # Evaluate agents with weights from population and collect rewards\n",
    "        rewards = np.array([agent.evaluate(weights, gamma=train_gamma, max_iters=max_eval_iterations) \n",
    "                            for weights in weights_population])\n",
    "        # Select elite\n",
    "        elite_idxs = rewards.argsort()[-n_elite:] # indexes of elite\n",
    "        elite_weights = [weights_population[i] for i in elite_idxs]\n",
    "        # Calculate best weights as mean of all elite weights\n",
    "        best_weight = np.array(elite_weights).mean(axis=0)\n",
    "        \n",
    "        reward = agent.evaluate(best_weight, gamma=1.0, max_iters=max_eval_iterations)\n",
    "        scores_deque.append(reward)\n",
    "        scores.append(reward)\n",
    "        if best_reward < reward:\n",
    "            best_reward = reward\n",
    "            save_agent_weights(agent, filename='cem_weights_agent.pt')\n",
    "            \n",
    "        if (iteration % log_interval) == 0:\n",
    "            print(f\"Episode {iteration}\\tAverage Score: {round(np.mean(scores_deque), 2)}\")\n",
    "\n",
    "        if np.mean(scores_deque) >= 395.0:\n",
    "            print(f'\\nEnvironment solved in {iteration} iterations!')\n",
    "            print(f\"Average Score: {round(np.mean(scores_deque), 2)}\")\n",
    "            print(f\"Best Score: {round(best_reward, 2)}\")\n",
    "            break\n",
    "            \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State size: 4, action size: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CEM_Agent(\n",
       "  (_net): Sequential(\n",
       "    (fc1): Linear(in_features=4, out_features=10, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (fc2): Linear(in_features=10, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Agent\n",
    "agent = CEM_Agent(env, device=device, h_size=10)\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49bb2af4fdd147f997de1a4662424a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\airen\\Anaconda3\\envs\\pycharmenv\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights successfully saved.\n",
      "Weights successfully saved.\n",
      "Weights successfully saved.\n",
      "Weights successfully saved.\n",
      "Weights successfully saved.\n",
      "Episode 10\tAverage Score: 111.7\n",
      "Weights successfully saved.\n",
      "Episode 20\tAverage Score: 305.85\n",
      "Episode 30\tAverage Score: 370.57\n",
      "\n",
      "Environment solved in 37 iterations!\n",
      "Average Score: 395.05\n",
      "Best Score: 500.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAfvklEQVR4nO3de5CcdZ3v8fd3rrlMLpPMhZAEEiSEAEKCY5TFCwoIrpfgukqUdWPJVnQ33qq2ygV3z1ndOqliPWddt85ZZFFZI6tgdlFJqaWGyM0VCROMQC6TBAIkJOmemSRMzyTTc/ueP/rpTifTM9NzeaZ7nv68qqjufvrpztcH7E9+v9/z+/3M3REREQEoK3QBIiJSPBQKIiKSoVAQEZEMhYKIiGQoFEREJKOi0AWMR11dnS9ZsqTQZYiITCk7duxoc/f6XO9N6VBYsmQJzc3NhS5DRGRKMbNXhnpP3UciIpKhUBARkQyFgoiIZCgUREQkQ6EgIiIZoYaCmb1sZs+b2U4zaw6OzTOzrWa2P3iszTr/TjM7YGYtZnZTmLWJiMhgk9FSeJe7r3T3puD1HcA2d18GbAteY2aXAWuBy4GbgbvNrHwS6hMRkUAh5imsAa4Lnm8CHgP+Jjj+oLsngYNmdgBYDTxVgBpllF547XV+tetYocsQKRmXnDeL9195/oR/b9ih4MCvzMyBf3P3e4FGdz8K4O5HzawhOHch8Luszx4Ojp3FzNYD6wEuuOCCMGuXUfiXbfvZujuGWaErESkN77/y/CkZCte6+5Hgh3+rme0d5txcPyeDdgAKguVegKamJu0QVCRiHd2845J6vvep1YUuRUTGIdQxBXc/EjzGgR+T6g6KmdkCgOAxHpx+GFic9fFFwJEw65OJE+9I0jCrutBliMg4hRYKZjbTzGalnwPvAV4AtgDrgtPWAQ8Hz7cAa82s2syWAsuA7WHVJxNnYMBp7UzSOFuhIDLVhdl91Aj82FKdzBXAD9z9F2b2DLDZzG4HXgU+AuDuu8xsM7Ab6AM2uHt/iPXJBGnv6qF/wGmYNa3QpYjIOIUWCu7+EnBVjuPtwPVDfGYjsDGsmiQc8UQ3gFoKIhGgGc0ybvFEEoB6tRREpjyFgoxbvCPVUtBAs8jUp1CQcYt3pFoKDeo+EpnyFAoybrFEN3NnVFJdoVVJRKY6hYKMm+YoiESHQkHGLZ5I0jhbg8wiUaBQkHGLd3RTr5aCSCQoFGRc3FOzmTVxTSQaFAoyLidO9dLb75q4JhIRCgUZl1hmjoJaCiJRoFCQcUnPZlZLQSQaFAoyLnG1FEQiRaEg45JuKWg2s0g0KBRkXOId3cyeVsG0Ss1mFokChYKMS6wjSYMmrolEhkJBxiWe6NYSFyIRolCQcdESFyLRolCQMXN3LYYnEjEKBRmz10/30tM/oDEFkQhRKMiYZW5HVUtBJDIUCjJmMW3DKRI5CgUZs/Q2nBpoFokOhYKMmWYzi0SPQkHGLNbRTU11BTOqKgpdiohMEIWCjFlrIqlWgkjEKBRkzGIdms0sEjUKBRmzeELbcIpEjUJBxsTdiSe6tbmOSMQoFGRMOrr76O4dUEtBJGIUCjImrYlg4ppaCiKRolCQMUlPXFNLQSRaQg8FMys3s9+b2U+D1/PMbKuZ7Q8ea7POvdPMDphZi5ndFHZtMnYxtRREImkyWgpfAPZkvb4D2Obuy4BtwWvM7DJgLXA5cDNwt5lpj8cipSUuRKIp1FAws0XA+4BvZx1eA2wKnm8Cbsk6/qC7J939IHAAWB1mfTJ28USSGVXl1FRrNrNIlITdUvgG8CVgIOtYo7sfBQgeG4LjC4FDWecdDo5JEdLENZFoCi0UzOz9QNzdd+T7kRzHPMf3rjezZjNrbm1tHVeNMnbxRFKb64hEUJgthWuBD5rZy8CDwLvN7D+AmJktAAge48H5h4HFWZ9fBBw590vd/V53b3L3pvr6+hDLl+HE1VIQiaTQQsHd73T3Re6+hNQA8q/d/c+ALcC64LR1wMPB8y3AWjOrNrOlwDJge1j1yfhoiQuRaCrEKOFdwGYzux14FfgIgLvvMrPNwG6gD9jg7v0FqE9G0Jns41RPv5a4EImgSQkFd38MeCx43g5cP8R5G4GNk1GTjF1mG06FgkjkaEazjFpmjoK6j0QiR6EgoxbXbGaRyFIoyKilWwr1aimIRI5CQUYtnuhmWmUZs6dpNrNI1CgUZNTSt6Oa5ZpvKCJTmUJBRk1LXIhEl0JBRi2eSGp1VJGIUijIqMU7ktSrpSASSQoFGZVTPX10JvvUUhCJKIWCjMqZbTjVUhCJIoWCjIqWuBCJNoWC8J/Nh/jUd5/BfdD2FYPEE9qGUyTKFArCUy+28+u9cfbFOkc8Nx0K6j4SiSaFgtDW1QPAI3tiI54b7+imqqKMOdMrwy5LRApAoSC0BX/737o7j1BIJGmYVa3ZzCIRpVAQ2ruSlBnsPHQyswLqUOIJzWYWiTKFQolzd9o7e7hueQMAj+6ND3t+rEPbcIpEmUKhxHWc7qNvwLn24joWzp3O1t3Dh0K8o1vbcIpEmEKhxLV2psYT6mqquGFFA7850MrpntxbY3f39tPR3UeDbkcViSyFQolrz4RCNTdc1kh37wD/faAt57mazSwSfQqFEtce3I46v6aKtyydT011xZC3pp7ZhlMtBZGoUiiUuHRLYf7Maqoqynjn8noe2RNnYGDw7OaYWgoikadQKHFtnT2YQe2M1GS0G1c00taZ5A+HTw46N91S0BIXItGlUChxbZ1J5s2ooqI89Z/CdcvrKS+znF1I8USSynLLBIiIRI9CocS1d/Ywv6Yq83rujCrevKSWR3Lcmhrr6Ka+RrOZRaJMoVDi2ruSzJ959hjBDSsaaYkleLX91FnHWxNJDTKLRJxCocSd21IAuPGyRmDwAnnxjqQGmUUiTqFQ4lo7k9TVnP1Df+H8mSxrqGHb3rNDIZbo1iCzSMQpFEpYsq+fRHcfdee0FABuuKyRp186zuunezPnnjzVq5aCSMQpFErY8czEtcE/9DesaKRvwHl8XyuQNZtZ6x6JRJpCoYS1dwahMHNwS2Hl4rnU1VTxSLDHQmbHNXUfiUSaQqGEtaVnM+doKZSXGe++tIFHW+L09g/Qml7iQt1HIpEWWiiY2TQz225mfzCzXWb21eD4PDPbamb7g8farM/caWYHzKzFzG4KqzZJaQtaCvU5QgFSXUiJ7j6eOXg8a4kLtRREoizMlkISeLe7XwWsBG42s7cCdwDb3H0ZsC14jZldBqwFLgduBu42s/IQ6yt5mXWPcgw0A7xtWR1VFWVs3RMjnuimvMxydjWJSHSEFgqe0hm8rAz+cWANsCk4vgm4JXi+BnjQ3ZPufhA4AKwOqz5JrZA6rbKMGVW5s3dGVQVvu7iOR/bEiHUkqa+ppqxMs5lFoizUMQUzKzeznUAc2OruTwON7n4UIHhsCE5fCBzK+vjh4Ni537nezJrNrLm1tTXM8iOvrTM1m3m4ZStuWNHIoeOneerFdt15JFICQg0Fd+9395XAImC1mV0xzOm5fpkGrd/s7ve6e5O7N9XX109UqSWprbMn5xyFbNevSGX2aydPazxBpARMyt1H7n4SeIzUWEHMzBYABI/pldcOA4uzPrYIODIZ9ZWq9hyzmc/VOHsaVy2aA2iOgkgpCPPuo3ozmxs8nw7cAOwFtgDrgtPWAQ8Hz7cAa82s2syWAsuA7WHVJ7nXPcrlhhWptZAa1VIQibwwWwoLgEfN7DngGVJjCj8F7gJuNLP9wI3Ba9x9F7AZ2A38Atjg7rl3kJdxc/fUCqkjtBQA3nP5eQAsqp0edlkiUmAVYX2xuz8HrMpxvB24fojPbAQ2hlWTnNHR3Udvv+d1i+ny82bxkw3XctmC2ZNQmYgUUmihIMUtPZt5pDGFtJWL54ZZjogUiby7j8xsupktD7MYmTzpdY/yDQURKQ15hYKZfQDYSaqvHzNbaWZbwixMwjXSbGYRKU35thS+Qmp28UkAd98JLAmnJJkMbZllsxUKInJGvqHQ5+6vh1qJTKq2RBIzmDdDoSAiZ+Q70PyCmX0cKDezZcDngd+GV5aErb0rSe2MKirKtXq6iJyR7y/C50itXpoEfgC8DnwxrKIkfO2dPVrxVEQGGbGlECxfvcXdbwD+NvySZDLkO5tZRErLiC2FYFbxKTObMwn1yCRpy3M2s4iUlnzHFLqB581sK9CVPujunw+lKgldWyJJ3cVqKYjI2fINhZ8F/0gE9PQN0NHdp4lrIjJIXqHg7pvMrAq4JDjU4u694ZUlYTqemaOgUBCRs+UVCmZ2HamtM18mtRnOYjNb5+5PhFeahKVNs5lFZAj5dh/9E/Aed28BMLNLgAeAN4VVmITnzGJ4CgUROVu+8xQq04EA4O77gMpwSpKwpRfDmz9T3UcicrZ8WwrNZvYd4P7g9W3AjnBKkrC1dwUthVkKBRE5W76h8JfABlLLWxjwBHB3WEVJuNo7e6iuKGNmVXmhSxGRIpNvKFQA/+LuX4fMLGf9NXOKauvsoa6mGjMrdCkiUmTyHVPYBmRv0DsdeGTiy5HJ0NaZ1J1HIpJTvqEwzd070y+C5zPCKUnC1t6V1GJ4IpJTvqHQZWZXp1+YWRNwOpySJGztQfeRiMi58h1T+CLwn2Z2BHDgfODW0KqS0Lh7sEKqQkFEBhu2pWBmbzaz89z9GeBS4IdAH6m9mg9OQn0ywTq6++jpH9DENRHJaaTuo38DeoLn1wBfBv4VOAHcG2JdEpJ2LXEhIsMYqfuo3N2PB89vBe5194eAh8xsZ7ilSRjag8XwNKYgIrmM1FIoN7N0cFwP/DrrvXzHI6SIZFoKWuJCRHIY6Yf9AeBxM2sjdbfRkwBmdjGpfZplimnrTLcU1H0kIoMNGwruvtHMtgELgF+5uwdvlQGfC7s4mXjpFVJrNU9BRHIYsQvI3X+X49i+cMqRsLV39jB3RiWV5flOURGRUqJfhhLT3pXUILOIDEmhUGLaOnu0xIWIDCm0UDCzxWb2qJntMbNdZvaF4Pg8M9tqZvuDx9qsz9xpZgfMrMXMbgqrtlLW1qmWgogMLcyWQh/w1+6+AngrsMHMLgPuALa5+zJSq6/eARC8txa4HLgZuDtYolsmUGqJC7UURCS30ELB3Y+6+7PB8wSwB1gIrAE2BadtAm4Jnq8BHnT3pLsfBA4Aq8OqrxT19A3w+ulezVEQkSFNypiCmS0BVgFPA43ufhRSwQE0BKctBA5lfexwcOzc71pvZs1m1tza2hpm2ZFz4lQwR2GWWgoiklvooWBmNcBDwBfdvWO4U3Mc80EH3O919yZ3b6qvr5+oMktCm2Yzi8gIQg0FM6skFQjfd/cfBYdjZrYgeH8BEA+OHwYWZ318EXAkzPpKjWYzi8hIwrz7yIDvAHvSezsHtgDrgufrgIezjq81s2ozWwosA7aHVV8pOrNCqloKIpJbmIvaXQt8Ang+a0XVLwN3AZvN7HbgVeAjAO6+y8w2A7tJ3bm0wd37Q6yv5LQHLQXdfSQiQwktFNz9N+QeJ4DUiqu5PrMR2BhWTaWurStJVUUZs6q1wK2I5KYZzSWkLdFD3cwqUj17IiKDKRRKSHtXUuMJIjIshUIJ0WxmERmJQqGEtHcmNUdBRIalUCgR7k5bV49mM4vIsBQKJSKR7KOnb4A6tRREZBgKhRKhOQoikg+FQonQbGYRyYdCoURo3SMRyYdCoUSkV0jVrmsiMhyFQolIjynUzlBLQUSGplAoEe1dSeZMr6SqQv/KRWRo+oUoEZrNLCL5UCgU0G9fbOMdX3uU10/3hv5ntXUmNZ4gIiNSKBTQ4/taefX4KXYeOhn6n5UKBbUURGR4CoUC2ncsAcALr70e+p/V3tWjdY9EZEQKhQJqCULh+cPhhkJv/wAnT/VqTEFERqRQKJCO7l6OvN4NwPMhtxROdKWXuFBLQUSGp1AokP2xVCth9dJ5vHbyNMeDH+4wtAYT1+rVUhCRESgUCmRv0HX0p29aBITbWjizGJ5aCiIyPIVCgew7lmBmVTk3XX4eEO5gc3tXsBjeTLUURGR4CoUC2XsswSXnzWLO9EqWzJ8R6mCzWgoiki+FQgG4O/tiCS49bxYAVyycE2r3UVtnD1XlZcyeVhHanyEi0aBQKIDWziQnTvVySWMqFN64cE6og81tnUnm11RhZqF8v4hEh0KhANLzE5YHLYU3LpoDhDfY3B6EgojISBQKBZAJhcYz3UcQ3mCzZjOLSL4UCgXQcixBXU1VZuB39rRwB5u1QqqI5EuhUAD7YolM11FaWIPN7k5rZ5J63XkkInlQKEyygQFnX6wzM8icFtZg845XTtDTN8CSupkT+r0iEk0KhUl26MQpTvf2Z25HTQtrsPmex19k7oxK1qw8f0K/V0SiSaEwydKDzOe2FMIYbN4XS/DInjjrrlnCjCrNURCRkYUWCmZ2n5nFzeyFrGPzzGyrme0PHmuz3rvTzA6YWYuZ3RRWXYU2VCiEMdh8z+MvMr2ynHV/tGTCvlNEoi3MlsJ3gZvPOXYHsM3dlwHbgteY2WXAWuDy4DN3m1l5iLUVTEssweJ505lZPfhv7hM52PzaydNs2XmEW9+8mHla80hE8hRaKLj7E8Dxcw6vATYFzzcBt2Qdf9Ddk+5+EDgArA6rtkJqOZZgeePsnO9N5GDzd548CMBfvH3puL9LRErHZI8pNLr7UYDgsSE4vhA4lHXe4eDYIGa23syazay5tbU11GInWrKvn4NtXSw/rybn+xM12Hyiq4cHtr/KB686n0W1M8b1XSJSWoploDnXojye60R3v9fdm9y9qb6+PuSyJtbBti76BnzQeELaRA02f++pVzjd28+n3/mGcX2PiJSeyQ6FmJktAAge48Hxw8DirPMWAUcmubbQpQeZLz0vd/fRRAw2n+rp47u/Pcj1lzYMmiAnIjKSyQ6FLcC64Pk64OGs42vNrNrMlgLLgO2TXFvoWo4lqCgzlg4zkWy8g82bnznEiVO9/OV1aiWIyOiFeUvqA8BTwHIzO2xmtwN3ATea2X7gxuA17r4L2AzsBn4BbHD3/rBqK5SWYwneUF9DVcXQl308g829/QN868mDNF1YS9OSeeMpVURKVGgzmtz9Y0O8df0Q528ENoZVTzFoiSVYdUHtsOdkDza/85LRjZn89LkjvHbyNP+w5vIx1ygipa1YBpojrzPZx+ETpwctb3GusQ42uzv3PPYSlzTW8K7lDSN/QEQkB4XCJNkXyz2T+VxjHWx+tCVOSyzBZ975BsrKtMOaiIyNQmGS7MvceTTyHUFjGWy+57GXWDh3Oh+4SgvficjYKRQmyd5jCWZUlbNw7vQRzx3tYPOOV46z/eXj/MXbl1JZrn+lIjJ2+gWZJPtiCZY1zsqra2e0M5u/+dhL1M6o5NY3Lx75ZBGRYSgUJknLsQSXjjCekDaaweb9sQSP7Imx7o+0PLaIjJ9CYRK0dSZp7+rhkjxnGOc72NyZ7OOLP9xJTXUF665ZMgGVikipUyhMgtEMMqeNNNjc1z/Ahu8/y95jCf7vx1dRq+WxRWQCKBQmwd4hNtYZznCDze7O3/3kBR7f18r/uuUKzUsQkQmjUJgE+2IJ5s+son5Wdd6fGW6w+e7HXuTBZw7x2XddzMdWXzBhdYqIKBQmwd5jiVG1EmDoweYf//4w//uXLXxo1UL++j2XTFiNIiKgUAjdwICzP5YY9TLWuQabf/tiG1/6r+e45qL5/OOHr8RMM5dFZGIpFEL22snTdPX0j2lvg+zB5n2xBJ++fwdL5s/knk+8adiVVkVExkq/LCFrGcMgc1p6sHnP0Q4+ed92pleW891PrWbO9MqJLlNEBAhx6WxJackshJd7X+bhpAebP/6t35HsG2Dzp6/Ja5kMEZGxUiiErOVYgoVzpzNr2uj/dp8ebO7o7uPb65oyr0VEwqJQCNm+WGJUk9ayzZ5WyaeuXcpVi+doLoKITAqFQoh6+wd4sbWTd1069h/0//mByyawIhGR4WmgOUQH27ro7fcxtxRERCabQiFE47nzSESkEBQKIWo5lqC8zLiofmahSxERyYtCIUR7jnZwUd1MqivKC12KiEheNNCcQ7Kvnzseep7XTp7mvVecxx+/cQGNs6fl9dkTXT08vPM1NjcfZvfRDtZqNzQRmULM3Qtdw5g1NTV5c3PzhH7n6Z5+1t/fzJP727iobiYvtXVhBk0X1vK+Ny7gvTkCon/AeWJ/K//VfJitu2P09A9wxcLZfLRpMR++ehEzq5W9IlI8zGyHuzflfE+hcEaiu5fbv9tM8yvHuevDV/LRpsUciHfy8+eP8rPnjtISS5wVEKsuqOWXu47xo2df41hHN7UzKvnQqkV8pGkRKxbMnrC6REQmkkIhDydP9fDn921n95EOvrF2Je+/8vxB55wbEABlBtctb+CjTYt496WNWqhORIqeQmEErYkkn/jO07zU1sU3b7ua61c0jviZA/FO/nDoJG9bVpf3eIOISDEYLhRKvrP7yMnT3Pbtpzn2ejf//sk3c+3FdXl97uKGGi5uGP0idyIixaykQ+GV9i4+/q2n6Tjdy/23r6ZpybxClyQiUlAlGwr7Ywlu+/bT9PYP8MD6t2oFUhERSjQU9hzt4LZvP01FmfHDT1+jZShERAJFd6uMmd1sZi1mdsDM7gjjz6irqeby82ezWYEgInKWomopmFk58K/AjcBh4Bkz2+Luuyfyz6mfVc39t79lIr9SRCQSiq2lsBo44O4vuXsP8CCwpsA1iYiUjGILhYXAoazXh4NjIiIyCYotFCzHsbNm15nZejNrNrPm1tbWSSpLRKQ0FFsoHAaylxVdBBzJPsHd73X3Jndvqq+vn9TiRESirthC4RlgmZktNbMqYC2wpcA1iYiUjKK6+8jd+8zss8AvgXLgPnffVeCyRERKRlGFAoC7/xz4eaHrEBEpRcXWfSQiIgU0pZfONrNW4JUh3q4D2iaxnLGaKnXC1KlVdU6sqVInTJ1aC13nhe6e806dKR0KwzGz5qHWCy8mU6VOmDq1qs6JNVXqhKlTazHXqe4jERHJUCiIiEhGlEPh3kIXkKepUidMnVpV58SaKnXC1Km1aOuM7JiCiIiMXpRbCiIiMkoKBRERyYhkKEzG7m0TwcxeNrPnzWynmTUXup40M7vPzOJm9kLWsXlmttXM9gePtYWsMW2IWr9iZq8F13Wnmf1xIWsMalpsZo+a2R4z22VmXwiOF9V1HabOorqmZjbNzLab2R+COr8aHC+26zlUnUV1PbNFbkwh2L1tH1m7twEfm+jd2yaCmb0MNLl7UU22MbN3AJ3A99z9iuDY14Dj7n5XELS17v43hawzqCtXrV8BOt39/xSytmxmtgBY4O7PmtksYAdwC/BJiui6DlPnRymia2pmBsx0904zqwR+A3wB+BOK63oOVefNFNH1zBbFloJ2bxsnd38COH7O4TXApuD5JlI/FAU3RK1Fx92PuvuzwfMEsIfUBlJFdV2HqbOoeEpn8LIy+Mcpvus5VJ1FK4qhMJV2b3PgV2a2w8zWF7qYETS6+1FI/XAADQWuZySfNbPngu6loujqSjOzJcAq4GmK+LqeUycU2TU1s3Iz2wnEga3uXpTXc4g6ociuZ1oUQ2HE3duKyLXufjXwXmBD0BUi4/dN4A3ASuAo8E+FLecMM6sBHgK+6O4dha5nKDnqLLpr6u797r6S1GZcq83sikLXlMsQdRbd9UyLYiiMuHtbsXD3I8FjHPgxqa6vYhUL+pvT/c7xAtczJHePBf9HHAC+RZFc16BP+SHg++7+o+Bw0V3XXHUW6zUFcPeTwGOk+umL7nqmZddZzNcziqEwJXZvM7OZwUAeZjYTeA/wwvCfKqgtwLrg+Trg4QLWMqz0j0LgQxTBdQ0GHL8D7HH3r2e9VVTXdag6i+2amlm9mc0Nnk8HbgD2UnzXM2edxXY9s0Xu7iOA4Paub3Bm97aNBS5pEDO7iFTrAFKbHf2gWOo0sweA60gt7xsD/h74CbAZuAB4FfiIuxd8gHeIWq8j1Sx34GXg0+l+5kIxs7cBTwLPAwPB4S+T6q8vmus6TJ0fo4iuqZldSWoguZzUX243u/s/mNl8iut6DlXn/RTR9cwWyVAQEZGxiWL3kYiIjJFCQUREMhQKIiKSoVAQEZEMhYKIiGQoFKQkmVl/1gqVO22E1XTN7DNm9ucT8Oe+bGZ1Y/jcTcHKmrVm9vPx1iEylIpCFyBSIKeDpQfy4u73hFlMHt4OPAq8A/jvAtciEaZQEMkSLGf+Q+BdwaGPu/uB7OW4zezzwGeAPmC3u681s3nAfcBFwClgvbs/F0ymegCoB7aTtTaXmf0Z8HmgitQktr9y9/5z6rkVuDP43jVAI9BhZm9x9w+GcQ2ktKn7SErV9HO6j27Neq/D3VcD/4/UzPhz3QGscvcrSYUDwFeB3wfHvgx8Lzj+98Bv3H0VqSUYLgAwsxXAraQWRVwJ9AO3nfsHufsPgauBF9z9jaSWQ1ilQJCwqKUgpWq47qMHsh7/Ocf7zwHfN7OfkFr+A+BtwIcB3P3XZjbfzOaQ6u75k+D4z8zsRHD+9cCbgGdSyw0xnaEXb1sGvBg8nxHscyASCoWCyGA+xPO095H6sf8g8D/M7HKGX7I913cYsMnd7xyuEEtt01oHVJjZbmBBsDb/59z9yeH/Z4iMnrqPRAa7Nevxqew3zKwMWOzujwJfAuYCNcATBN0/ZnYd0BbsQ5B9/L1AejOVbcCfmllD8N48M7vw3ELcvQn4GanxhK8Bf+vuKxUIEha1FKRUTQ/+xp32C3dP35ZabWZPk/pL08fO+Vw58B9B15AB/+zuJ4OB6H83s+dIDTSnl2/+KvCAmT0LPE5q5U7cfbeZ/R2pnffKgF5gA/BKjlqvJjUg/VfA13O8LzJhtEqqSJbg7qMmd28rdC0ihaDuIxERyVBLQUREMtRSEBGRDIWCiIhkKBRERCRDoSAiIhkKBRERyfj/OwNke1oBCEwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = CEM_Weights(agent=agent)\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
